{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8445750e-f98b-4e89-a182-753caeabf47e",
   "metadata": {},
   "source": [
    "# Booter Website Classification using AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777dd8f5-c9f8-44a5-8d19-6e1fce3b7295",
   "metadata": {},
   "source": [
    "Last updated: 11/02/2025\n",
    "\n",
    "Several academic papers have explored the classification of websites that offer DDoS-as-a-Service attacks, commonly known as Booter Websites. Notable examples include:\n",
    "1. J. J. Chromik, J. J. Santanna, A. Sperotto, and A. Pras. **Booter Websites Characterization: Towards a List of Threats.** Brazilian Symposium on Computer Networks and Distributed Systems (SBRC), 2015.\n",
    "2. J. J. Santanna, R. de O. Schmidt, D. Tuncer, J. de Vries, L. Granville, and A. Pras. **Booter Blacklist: Unveiling DDoS-for-Hire Websites.** International Conference on Network and Service Management (CNSM), 2016.\n",
    "3. J. J. Santanna, R. de O. Schmidt, D. Tuncer, J. de Vries, L. Zambenedetti Granville, and A. Pras. **Booter List Generation: The Basis for Investigating DDoS-for-Hire Websites.** International Journal on Network Management (IJNM), 2017.\n",
    "\n",
    "These studies were consolidated into **Chapter 2** of:\n",
    "- J. J. Santanna. **DDoS-as-a-Service: Investigating Booter Websites.** PhD Thesis, University of Twente.\n",
    "  - Download here: https://bit.ly/jjsantanna_thesis\n",
    "  - Source code: https://github.com/jjsantanna/Booter-black-List/tree/master/Classifier\n",
    "\n",
    "### Opportunity\n",
    "#### With advancements in Large Language Models (LLMs), we aim to explore whether LLMs provide a more efficient and accurate approach for the automated classification of Booter Websites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d178c4fb-2710-409a-afeb-6232db05e01f",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "1. Get list of URLs to be classified as booter or not:\n",
    "    1. Offline.\n",
    "        1. Get an offline list of URLs (ex. https://github.com/jjsantanna/booters_ecosystem_analysis/blob/master/booterblacklist.csv)\n",
    "        2. Get latest snapshot of an URL from Web Archive (https://webcf.waybackmachine.org/); Check the status 301 & 302 (redirect); Get the redirected URL if exist\n",
    "    2. Online.\n",
    "        1. VPN connection from different location (from a list of countries)\n",
    "        2. Get a list of URLs/Websites using Google search for 'booter', 'stresser'\n",
    "    \n",
    "2. Classify URL whether a booter or not: \n",
    "    1. Visual approach.\n",
    "        1. Take a screenshot of the landing page of an URL\n",
    "        2. Use a Visual (or multimodal) LLM to classify the image as a Booter Webpage\n",
    "    2. Text approach.\n",
    "        1. Scrape URL\n",
    "        2. Use a Text LLM to classify the content whether a Booter Webpage or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ff312-3351-4bd2-8fe0-11f4db8fa67d",
   "metadata": {},
   "source": [
    "## 1.A.a. Get an offline list of booter websites from the https://bit.ly/jjsantanna_thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "197a80c5-565f-447b-8084-0f2067a485ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>booter_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x-booter.pw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123boot.pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1606-stresser.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9yrbrfyd.esy.es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absolut-stresser.net</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             booter_url\n",
       "0          0x-booter.pw\n",
       "1           123boot.pro\n",
       "2     1606-stresser.net\n",
       "3       9yrbrfyd.esy.es\n",
       "4  absolut-stresser.net"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://githubraw.com/jjsantanna/booters_ecosystem_analysis/master/booterblacklist.csv\"\n",
    "df = pd.read_csv(url, storage_options={\"User-Agent\": \"Mozilla/5.0\"},index_col=0, names=[\"id\", \"booter_url\"], header=None).reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b86df6-34f1-43b8-880b-6ac70e786674",
   "metadata": {},
   "source": [
    "## 1.A.b. Get lastest snapshot of an URL from Web Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e96da106-3639-4284-9afc-fd3854601700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from waybackpy import WaybackMachineCDXServerAPI\n",
    "from urllib.parse import unquote\n",
    "\n",
    "def get_latest_archived_info(url):\n",
    "    # Initialize the CDX Server API\n",
    "    cdx = WaybackMachineCDXServerAPI(url)\n",
    "    \n",
    "    # Retrieve the list of snapshots\n",
    "    snapshots = list(cdx.snapshots())\n",
    "    \n",
    "    if snapshots:\n",
    "        # Get the latest snapshot\n",
    "        latest_snapshot = snapshots[-1]\n",
    "        \n",
    "        # Extract the archive URL\n",
    "        archive_url = latest_snapshot.archive_url\n",
    "        \n",
    "        # Extract the HTTP status code\n",
    "        status_code = latest_snapshot.statuscode\n",
    "        \n",
    "        # Check if the status code indicates a redirect (3xx)\n",
    "        if status_code.startswith('3'):\n",
    "            try:\n",
    "                # Make a GET request to follow all redirects\n",
    "                response = requests.get(archive_url, \n",
    "                                     allow_redirects=True,\n",
    "                                     timeout=10)  # Added timeout\n",
    "                \n",
    "                # Get the final URL after all redirects\n",
    "                final_url = response.url\n",
    "                \n",
    "                # If it's a Wayback Machine URL, try to extract the original URL\n",
    "                if 'web.archive.org' in final_url:\n",
    "                    # Extract the original URL from the Wayback Machine URL\n",
    "                    parts = final_url.split('web.archive.org/web/')\n",
    "                    if len(parts) > 1:\n",
    "                        timestamp_and_url = parts[1]\n",
    "                        # Remove the timestamp (first 14 characters) to get the original URL\n",
    "                        redirect_url = unquote(timestamp_and_url[14:])\n",
    "                    else:\n",
    "                        redirect_url = final_url\n",
    "                else:\n",
    "                    redirect_url = final_url\n",
    "                \n",
    "                return {\n",
    "                    'archive_url': archive_url,\n",
    "                    'status_code': status_code,\n",
    "                    'redirect_url': redirect_url\n",
    "                }\n",
    "            \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                return {\n",
    "                    'archive_url': archive_url,\n",
    "                    'status_code': status_code,\n",
    "                    'redirect_url': None,\n",
    "                    'error': str(e)\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                'archive_url': archive_url,\n",
    "                'status_code': status_code,\n",
    "                'redirect_url': None\n",
    "            }\n",
    "    else:\n",
    "        return \"No archived version found.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2cb46f-f271-4c0b-9da4-d081762358b3",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ac408a07-00ee-4d70-bb2c-43b336a7d047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beststresser.com'"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = df['booter_url'][50]\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "35dff7e9-af14-4b8d-9f4f-bebe3d952ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://stressers.zone/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "15ad9b51-7226-4bcd-8319-cfcbf1fe3f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'archive_url': 'https://web.archive.org/web/20241225182607/https://stressers.zone/',\n",
       " 'status_code': '-',\n",
       " 'redirect_url': None}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "archived_url = get_latest_archived_info(url)\n",
    "archived_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98400fa4-d7cb-4cd4-84d2-108a3fc639e0",
   "metadata": {},
   "source": [
    "## 2.A.a Take a screenshot of the landingpage of an URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "d3aa385d-84b8-4309-a325-8e798970c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium pillow webdriver-manager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from PIL import Image\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "def format_filename_from_url(url):\n",
    "    # Remove '://' and replace '.' with '_'\n",
    "    formatted_url = url.replace('://', '_')\n",
    "    formatted_url = formatted_url.replace('/', '')\n",
    "    formatted_url = formatted_url.replace('.', '_')  # Replace all '.' with '_'\n",
    "    # Get current date in YYMMDD format\n",
    "    date_str = datetime.datetime.now().strftime('%y%m%d')\n",
    "    return f\"{formatted_url}_{date_str}.png\"\n",
    "\n",
    "def capture_screenshot(url, width=1920, height=1080):\n",
    "    output_filename = format_filename_from_url(url)\n",
    "    \n",
    "    # Configure Selenium WebDriver\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(f\"--window-size={width},{height}\")\n",
    "    chrome_options.add_argument(\"--hide-scrollbars\")\n",
    "\n",
    "    # Automatically install the correct ChromeDriver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(3)  # Allow the page to load\n",
    "\n",
    "        # Get total page height and resize window\n",
    "        total_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        driver.set_window_size(width, total_height)\n",
    "        time.sleep(2)\n",
    "\n",
    "        # Capture and save screenshot\n",
    "        driver.save_screenshot(output_filename)\n",
    "\n",
    "        # Optimize image quality using Pillow\n",
    "        img = Image.open(output_filename)\n",
    "        img.save(output_filename, quality=100)\n",
    "        return output_filename\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error:\", e)\n",
    "    \n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2c405-79c4-4d1c-9a2d-1c9b62fc64de",
   "metadata": {},
   "source": [
    "EXAMPLE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "649ff66d-ff69-40df-91a6-5d44bf9108a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://web.archive.org/web/20241225182607/https://stressers.zone/\n",
      "https_web_archive_orgweb20241225182607https_stressers_zone_250211.png\n"
     ]
    }
   ],
   "source": [
    "url = archived_url['archive_url']\n",
    "print(url)\n",
    "\n",
    "screenshot_path = capture_screenshot(url)\n",
    "print(screenshot_path)\n",
    "\n",
    "!open $screenshot_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c316ab-7a25-46bc-86f1-605a408f4afd",
   "metadata": {},
   "source": [
    "## 2.A.b Use a Ollama + LLaVA to classify the image as a Booter Webpage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d98dc6b1-7e57-46ee-acf9-40029a446995",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API_URL = \"http://localhost:11434/api/generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "1632720e-1680-4699-a488-afe5944c0486",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt1 = \"\"\"You are an AI assistant trained to analyze webpage images and classify them as either promoting booter (DDoS-for-hire) services or not. \n",
    "\n",
    "Some characteristics of Booter websites are:\n",
    "- The page explicitly offers DDoS-for-hire services (e.g., 'Booter', 'DDoS attack', 'IP stresser').\n",
    "- There is a login page (booters always require accounts).\n",
    "- The page has subscription plans (e.g., pricing tiers like 'Basic', 'Premium', 'VIP' for attack durations).\n",
    "- Subscription-based attack services with unclear ethical use.\n",
    "- Existence of 'Registration' button\n",
    "- Payment options for attacks (cryptocurrency, PayPal, etc.).\n",
    "- Marketing suggests malicious use (e.g., ‘Take down your enemies!’).\n",
    "- The page may presents itself as a ‘stress tester’ but lacks strong disclaimers about legal use.\n",
    "\n",
    "Anything different from a Booter website should get a 'False' classification.\n",
    "\n",
    "Output Format (JSON). Respond strictly in JSON format as follows:\n",
    "{\n",
    "  \"booter\": true | false,\n",
    "  \"confidence\": \"high\" | \"low\",\n",
    "  \"reason\": \"describe based on what you've classified this website\"\n",
    "}\n",
    "\n",
    "Ensure your response is accurate and concise, avoiding unnecessary speculation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ca39e563-47c1-4cb1-98c3-0e128742658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt3 = \"\"\"You are an AI assistant trained to analyze screenshots of webpages and paying close attention to the following characteristics.\n",
    "- Does the page offers or promotes DDoS, DDoS attack, IP stresser, Booter (instead of only describing what it is)?\n",
    "- Is there a login?\n",
    "- Is there a registration or sign up?\n",
    "- Does the page contais subscription plans, ex. pricing tiers like 'Basic', 'Premium', 'VIP'?\n",
    "- Does the page contains attack or stress duration?\n",
    "- Does the page describes attack power, ex. in Gbps, Gb/s, or Tbps?\n",
    "- Does the page contains concurrency number, ex. 2, 4, 10?\n",
    "- Does the page contains payment options, ex. cryptocurrency, PayPal ?\n",
    "- Does the page contains network protocol names, ex. TCP, UPD?\n",
    "- Does the page contains methods of attack, ex. TCP, UPD?\n",
    "- Does the page contains link to the terms of service page or similar?\n",
    "\n",
    "Output Format (JSON). Respond strictly in JSON format as follows:\n",
    "{\n",
    "  \"promotes_ddos\": true | false,\n",
    "  \"login\": true | false,\n",
    "  \"registration\": true | false,\n",
    "  \"subscription_plans\": true | false,\n",
    "  \"attack_duration\": true | false,\n",
    "  \"attack_power\": true | false,\n",
    "  \"payment_options\": true | false,\n",
    "  \"network_protocols\": true | false,\n",
    "  \"attack_methods\": true | false,\n",
    "  \"tos\": true | false,\n",
    "}\n",
    "\n",
    "Ensure your response is accurate and concise, avoiding unnecessary speculation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "630a2e24-7425-4ca8-a10a-282786801f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    # Keep the base64 encoding pure and simple\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def classify_image(image_path, prompt):\n",
    "    # Encode image to base64\n",
    "    base64_image = encode_image_to_base64(image_path)\n",
    "    \n",
    "    # Prepare the request with cache control headers\n",
    "    url = f\"http://localhost:11434/api/generate?t={int(time.time())}\"  \n",
    "    headers = {\n",
    "        'Cache-Control': 'no-cache, no-store, must-revalidate',\n",
    "        'Pragma': 'no-cache',\n",
    "        'Expires': '0'\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"llava\",\n",
    "        \"prompt\": prompt,\n",
    "        \"images\": [base64_image],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Send request to Ollama with cache control headers\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse the response\n",
    "        result = response.json()\n",
    "        return result['response']\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cbbd37-68ec-4667-8aa9-2a651288d848",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "294f249e-93c1-477c-a52f-8c9c07b131da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://web.archive.org/web/20241225182607/https://stressers.zone/\n",
      "https_web_archive_orgweb20241225182607https_stressers_zone_250211.png\n",
      " ```json\n",
      "{\n",
      "  \"promotes_ddos\": false,\n",
      "  \"login\": true,\n",
      "  \"registration\": true,\n",
      "  \"subscription_plans\": false,\n",
      "  \"attack_duration\": false,\n",
      "  \"attack_power\": false,\n",
      "  \"payment_options\": false,\n",
      "  \"network_protocols\": false,\n",
      "  \"attack_methods\": false,\n",
      "  \"tos\": true\n",
      "}\n",
      "``` \n"
     ]
    }
   ],
   "source": [
    "url = archived_url['archive_url']\n",
    "# url = 'https://www.akamai.com/glossary/what-is-a-ddos-booter'\n",
    "print(url)\n",
    "\n",
    "screenshot_path = capture_screenshot(url)\n",
    "print(screenshot_path)\n",
    "\n",
    "!open $screenshot_path\n",
    "\n",
    "image_analysis = classify_image(image_path, system_prompt3)\n",
    "print(image_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a48e7a-26cd-4d69-b0bc-fed724e0cbe7",
   "metadata": {},
   "source": [
    "## 2.B.a. Scrapping URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "69c77aa3-8d82-4f1f-ac5c-c2e085923cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crawl4ai\n",
    "# !crawl4ai-setup\n",
    "import asyncio\n",
    "from crawl4ai import AsyncWebCrawler, BrowserConfig, CrawlerRunConfig, CacheMode\n",
    "\n",
    "async def crawl4ai_crawl(url: str):\n",
    "    browser_conf = BrowserConfig(headless=True)  # Run in headless mode\n",
    "    run_conf = CrawlerRunConfig(cache_mode=CacheMode.BYPASS)\n",
    "\n",
    "    async with AsyncWebCrawler(config=browser_conf) as crawler:\n",
    "        result = await crawler.arun(url=url, config=run_conf)\n",
    "\n",
    "        if result.success:\n",
    "            return result.markdown_v2.raw_markdown  # Return extracted content\n",
    "        else:\n",
    "            return f\"Error: {result.error_message}\"  # Handle errors gracefully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb78a220-e4f8-470a-a5d3-12dba5a4ba18",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "bac56566-87b1-4262-acd8-c085b0ffcd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INIT].... → Crawl4AI 0.4.248\n",
      "[FETCH]... ↓ https://stressers.zone/... | Status: True | Time: 0.60s\n",
      "[SCRAPE].. ◆ Processed https://stressers.zone/... | Time: 12ms\n",
      "[COMPLETE] ● https://stressers.zone/... | Status: True | Total: 0.61s\n",
      "## [🚀 STRESSER.ZONE](https://stressers.zone/</> \"back-to-index\")\n",
      "  * [](https://stressers.zone/<#>)\n",
      "  * [](https://stressers.zone/<#>)\n",
      "  * [](https://stressers.zone/<#>)\n",
      "  * [](https://stressers.zone/<#>)\n",
      "  * [ Login](https://stressers.zone/<login> \"login\")\n",
      "  * [ Sign Up](https://stressers.zone/<register> \"register\")\n",
      "\n",
      "\n",
      "# DDoS IP Stresser / IP Booter\n",
      "## `STRESSERS.ZONE` is the best free IP Stresser / DDoS Booter service in 2025.\n",
      "[ Register now](https://stressers.zone/<register> \"register\") [ Learn more](https://stressers.zone/<#features> \"features\") [ Preview](https://stressers.zone/<#preview> \"preview\")\n",
      "## **🔰 IMPORTANT NOTICE 🔰️**\n",
      "Our previous domain, STRESSER.ZONE, is now dead. We are now operating under new domains: **[STRESSERS.ZONE](https://stressers.zone/<https:/stressers.zone>)** and **[STRESSERZONE.RU](https://stressers.zone/<https:/stresserzone.ru>)**. You can find all mirrors at **[STRESSER-MIRRORS.RU](https://stressers.zone/<https:/stresser-mirrors.ru>)**.\n",
      "## Features\n",
      "### IP Stresser APP\n",
      "Our latest generation IP Stresser app will ensure you a completely personalized experience. Custom origin, UA, request type are only a tiny part of available options!\n",
      "### Instant Stresser\n",
      "Powerful high bandwidth servers make your attack as stable and hard-hitting as possible. With our large DDoS capacity, we are one of the strongest IP Stresser !\n",
      "### Confidentiality\n",
      "Because your confidentiality is very important to us, our IP Stresser app is developed with privacy and security in mind. We don't keep any logs.\n",
      "## With `STRESSER.ZONE`, you'll be able to drop the most well-know Anti-DDoS protections\n",
      "![tcp-bypass-methods](https://stressers.zone/assets/img/tcpbypass.png)\n",
      "### TCP Bypass Methods\n",
      "Our TCP bypass methods are able to create valid connections and can bypass almost any Layer 4 firewalls.\n",
      "![udp-amp-methods](https://stressers.zone/assets/img/udpamplified.png)\n",
      "### UDP Amplified Methods\n",
      "We use the most well-known UDP amplification protocols. These methods can generate larger attacks.\n",
      "![cloudflare-bypass](https://stressers.zone/assets/img/jschallenge.png)\n",
      "### JS Challenge Bypass\n",
      "Our Layer 7 DDoS attack methods are able to bypass web protections like BlazingFast.io, Cloudflare.com, DDoS-Guard.net and Sucuri.net\n",
      "## SUBSCRIPTIONS\n",
      "Here you will find some of our subscriptions. Create your account for free to access the full list!\n",
      "###  `Free Plan`\n",
      "€0 / mo\n",
      "  * Concurrents — **1**\n",
      "  * Attack time — **120s**\n",
      "  * Layer 4\n",
      "  * Premium\n",
      "\n",
      "[ Register now](https://stressers.zone/</register> \"register\")\n",
      "###  `Premium 4`\n",
      "€80 / mo\n",
      "  * Concurrents — **4**\n",
      "  * Attack time — **2400s**\n",
      "  * Layer 4/7\n",
      "  * Premium\n",
      "\n",
      "[ Register now](https://stressers.zone/</register> \"register\")\n",
      "###  `Business 4`\n",
      "€180 / mo\n",
      "  * Concurrents — **10**\n",
      "  * Attack time — **3600s**\n",
      "  * Layer 4/7\n",
      "  * Premium\n",
      "\n",
      "[ Register now](https://stressers.zone/</register> \"register\")\n",
      "###  `Premium-Reseller 3`\n",
      "€550 / mo\n",
      "  * Concurrents — **30**\n",
      "  * Attack time — **7200s**\n",
      "  * Layer 4/7\n",
      "  * Premium\n",
      "\n",
      "[ Register now](https://stressers.zone/</register> \"register\")\n",
      "###  `Extreme 2`\n",
      "€1750 / mo\n",
      "  * Concurrents — **100**\n",
      "  * Attack time — **43200s**\n",
      "  * Layer 4/7\n",
      "  * Premium\n",
      "\n",
      "[ Register now](https://stressers.zone/</register> \"register\")\n",
      "###  `CUSTOM`\n",
      "€ -- / mo\n",
      "  * Concurrents — *\n",
      "  * Attack time — *\n",
      "  * Layer 4/7\n",
      "  * Premium\n",
      "\n",
      "[ Get a quote!](https://stressers.zone/</register> \"register\")\n",
      "![payment-methods](https://stressers.zone/assets/img/paymentgateways.png)\n",
      "## `STRESSER.ZONE` - Best Free IP Stresser 2025 🚀\n",
      "Leading professional DDoS IP Stresser for individual customers and resellers! We provide a free ip stresser / booter at registration! Our large DDoS capacity provides you a stable and reliable IP Stresser service!By subscribing to our service you opt for reliability and guaranteed power!Try our Free Stresser today, we have the most powerful free IP Stresser on the market, create an account and boot for free 🚀\n",
      "[Terms of services](https://stressers.zone/<tos> \"terms-of-services\") - [Telegram](https://stressers.zone/<https:/t.me/+5Ajb6FBWldI1OTRk> \"telegram-group\") - [Stresser-Mirrors.ru](https://stressers.zone/<https:/stresser-mirrors.ru> \"mirror-links\")\n",
      "Handcrafted by [STRESSER.ZONE](https://stressers.zone/<https:/stresserzone.ru> \"telegram-group\") - All rights reserved © 2019-2025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "url = \"https://stressers.zone/\"\n",
    "scrapped_text = asyncio.run(crawl4ai_crawl(url))\n",
    "print(scrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cb59587c-bc5b-41df-bea7-92cb0f9523a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ollama \n",
    "import ollama\n",
    "\n",
    "def ollama(model, system_prompt, user_prompt):\n",
    "    import ollama  # https://pypi.org/project/ollama/\n",
    "    import time\n",
    "    import json\n",
    "\n",
    "    try:\n",
    "        # Start interaction with the model\n",
    "        start_time = time.time()\n",
    "\n",
    "        response = ollama.chat(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': user_prompt}\n",
    "            ],\n",
    "            format='json'\n",
    "        )\n",
    "\n",
    "        execution_time = time.time() - start_time\n",
    "\n",
    "        # Parse and append execution time\n",
    "        response_content = json.loads(response['message']['content'])\n",
    "        response_content['execution_time'] = execution_time\n",
    "\n",
    "        return response_content\n",
    "\n",
    "    except ollama.ResponseError as e:\n",
    "        print('Error:', e.error)\n",
    "        if e.status_code == 404:\n",
    "            ollama.pull(model)\n",
    "            print(\"Re-run this and it will work! We pulled the model for you!\") \n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "690bf620-e9d0-4934-9380-8b27d8562add",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt4 = \"\"\"You are an AI assistant trained to analyze webpages formated in markdown (input) and paying close attention to the following characteristics.\n",
    "- Does the page offers or promotes DDoS, DDoS attack, IP stresser, Booter (instead of only describing what it is)?\n",
    "- Is there a login?\n",
    "- Is there a registration or sign up?\n",
    "- Does the page contais subscription plans, ex. pricing tiers like 'Basic', 'Premium', 'VIP'?\n",
    "- Does the page contains attack or stress duration?\n",
    "- Does the page describes attack power, ex. in Gbps, Gb/s, or Tbps?\n",
    "- Does the page contains concurrency number, ex. 2, 4, 10?\n",
    "- Does the page contains payment options, ex. cryptocurrency, PayPal ?\n",
    "- Does the page contains network protocol names, ex. TCP, UPD?\n",
    "- Does the page contains methods of attack, ex. TCP, UPD?\n",
    "- Does the page contains link to the terms of service page or similar?\n",
    "\n",
    "Based on the previous analysis can you conclude that this is a Booter Website offering DDoS attacks as a service ('booter_conclusion')? \n",
    "Please describe your reasoning for this conclusion ('booter_reason') and describe your confidence level as 'high' or 'low'.\n",
    "\n",
    "Output Format (JSON). Respond strictly in JSON format as follows:\n",
    "{\n",
    "  \"promotes_ddos\": true | false,\n",
    "  \"login\": true | false,\n",
    "  \"registration\": true | false,\n",
    "  \"subscription_plans\": true | false,\n",
    "  \"attack_duration\": true | false,\n",
    "  \"attack_power\": true | false,\n",
    "  \"payment_options\": true | false,\n",
    "  \"network_protocols\": true | false,\n",
    "  \"attack_methods\": true | false,\n",
    "  \"tos\": true | false,\n",
    "  \"booter_conclusion\": true | false,\n",
    "  \"booter_reason\": \"describe your reasons\",\n",
    "  \"confidence level\": 'high'| 'low'\n",
    "}\n",
    "\n",
    "Ensure your response is accurate and concise, avoiding unnecessary speculation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "a0098238-6a28-4549-8d45-3f52e9254e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'promotes_ddos': True,\n",
       " 'login': True,\n",
       " 'registration': True,\n",
       " 'subscription_plans': True,\n",
       " 'attack_duration': False,\n",
       " 'attack_power': True,\n",
       " 'payment_options': True,\n",
       " 'network_protocols': False,\n",
       " 'attack_methods': False,\n",
       " 'tos': True,\n",
       " 'booter_conclusion': True,\n",
       " 'booter_reason': \"This website promotes DDoS IP Stressing services with various subscription plans, including a 'Free Plan' that offers limited concurrents and attack time. The website also provides information on TCP bypass methods, UDP amplified methods, and JS challenge bypass methods. Additionally, it lists payment options and networks protocols are not described.\",\n",
       " 'confidence level': 'high',\n",
       " 'execution_time': 12.473520994186401}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'llama3.2'\n",
    "system_prompt = system_prompt4\n",
    "user_prompt = scrapped_text\n",
    "ollama(model, system_prompt, user_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
